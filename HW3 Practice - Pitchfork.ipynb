## Notes to self

- Adjust to PEP8 standards: https://www.python.org/dev/peps/pep-0008/
- Put notes about Why Naive Bayes earlier



```python
%matplotlib inline

import json

import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

pd.set_option('display.width', 500)
pd.set_option('display.max_columns', 30)

# set some nicer defaults for matplotlib
from matplotlib import rcParams

#these colors come from colorbrewer2.org. Each is an RGB triplet

dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),
                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),
                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),
                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),
                (0.4, 0.6509803921568628, 0.11764705882352941),
                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),
                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),
                (0.4, 0.4, 0.4)]



rcParams['figure.figsize'] = (10, 6)
rcParams['figure.dpi'] = 150
rcParams['axes.color_cycle'] = dark2_colors
rcParams['lines.linewidth'] = 2
rcParams['axes.grid'] = False
rcParams['axes.facecolor'] = 'white'
rcParams['font.size'] = 14
rcParams['patch.edgecolor'] = 'none'



def remove_border(axes=None, top=False, right=False, left=True, bottom=True):

    ax = axes or plt.gca()
    ax.spines['top'].set_visible(top)
    ax.spines['right'].set_visible(right)
    ax.spines['left'].set_visible(left)
    ax.spines['bottom'].set_visible(bottom)
    
    #turn off all ticks
    ax.yaxis.set_ticks_position('none')
    ax.xaxis.set_ticks_position('none')
    
    #now re-enable visibles
    if top:
        ax.xaxis.tick_top()
    if bottom:
        ax.xaxis.tick_bottom()
    if left:
        ax.yaxis.tick_left()
    if right:
        ax.yaxis.tick_right()
```


    ---------------------------------------------------------------------------

    ModuleNotFoundError                       Traceback (most recent call last)

    <ipython-input-2-59a3cb6b72b5> in <module>()
          3 import json
          4 
    ----> 5 import requests
          6 import pandas as pd
          7 import numpy as np
    

    ModuleNotFoundError: No module named 'requests'



```python
"""first, a note on scraping pitchfork: according to their robots.txt file, scraping is allowed,
as long as users aren't scraping any of their search pages.
User-agent: *
Allow: /
Disallow: /search/
Disallow: /search"""
```

## Scraping Pitchfork for Reviews


```python
#attempt with the pitchfork api failed, not sure why. will scrape myself
import pitchfork
from bs4 import BeautifulSoup
#p = pitchfork.search('trans am', 'liberation')

```


```python
#import the artists and albums from 'meddulla's github page
pitchfork_data = pd.read_csv(
    'https://gist.githubusercontent.com/meddulla/8277139/raw/f1595d50cada910d082bc1dfd8ef47ff49910cb3/pitchfork-reviews.csv',
           sep = ',')
pitchfork_data.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>album</th>
      <th>score</th>
      <th>reviewer</th>
      <th>url</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Burial</td>
      <td>Rival Dealer EP</td>
      <td>9.0</td>
      <td>Larry Fitzmaurice</td>
      <td>http://pitchfork.com/reviews/albums/18820-buri...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Thing</td>
      <td>BOOT!</td>
      <td>7.7</td>
      <td>Aaron Leitko</td>
      <td>http://pitchfork.com/reviews/albums/18735-the-...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lumbar</td>
      <td>The First And Last Days Of Unwelcome</td>
      <td>7.7</td>
      <td>Grayson Currin</td>
      <td>http://pitchfork.com/reviews/albums/18705-lumb...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bryce Hackford</td>
      <td>Fair</td>
      <td>7.0</td>
      <td>Nick Neyland</td>
      <td>http://pitchfork.com/reviews/albums/18789-bryc...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Waka Flocka Flame</td>
      <td>DuFlocka Rant 2</td>
      <td>7.1</td>
      <td>Miles Raymer</td>
      <td>http://pitchfork.com/reviews/albums/17760-waka...</td>
    </tr>
  </tbody>
</table>
</div>




```python
print('min/mean/max: ',pitchfork_data.score.min(), pitchfork_data.score.mean(), pitchfork_data.score.max())
print('# reviews: ',len(reviews))
```

    min/mean/max:  0.0 6.955978497748127 10.0
    # reviews:  6884
    


```python
#pull soup of text from a pitchfork review link
#can delete this cell
from bs4 import BeautifulSoup
import requests
r = requests.get(reviews.url[0])
soup = BeautifulSoup(r.text, 'lxml')
```


```python
#input: urls in a pandas series format
#output: review text for each of those links as an array of strings

def get_multiple_reviews(urls):
    if isinstance(urls, pd.Series):
        review_text = []
        for link in urls:
            #pull url html into a beautifulsoup object
            r = requests.get(link)
            soup = BeautifulSoup(r.text, 'lxml')
            #pull all paragraph tags/contents with soup.findAll, and then put the text into one string
            

            review_text.append('\n\n'.join(map(str, [i.text for i in soup.findAll('p')])))
        

        return review_text
    else:
    
        print('Check inputs - confirm they\'re in pd.Series format')
        return

```


```python
#scraping pitchfork takes a while, so let's just sample a few hundred reviews
sample_df = pitchfork_data.sample(2000)
sample_reviews = get_multiple_reviews(sample_df.url)

```


```python
sample_df['review'] = sample_reviews
sample_df.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>album</th>
      <th>score</th>
      <th>reviewer</th>
      <th>url</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3454</th>
      <td>Flying</td>
      <td>Faces of the Night</td>
      <td>5.8</td>
      <td>Andrew Gaerig</td>
      <td>http://pitchfork.com/reviews/albums/11490-face...</td>
      <td>After playing avant-pop that fused Brooklyn's ...</td>
    </tr>
    <tr>
      <th>3584</th>
      <td>Arp</td>
      <td>In Light</td>
      <td>7.6</td>
      <td>Mark Richardson</td>
      <td>http://pitchfork.com/reviews/albums/11353-in-l...</td>
      <td>Former Tussle member Alexis Georgopoulos reinv...</td>
    </tr>
    <tr>
      <th>2855</th>
      <td>The Very Best</td>
      <td>Warm Heart of Africa</td>
      <td>8.6</td>
      <td>Brian Howe</td>
      <td>http://pitchfork.com/reviews/albums/13518-warm...</td>
      <td>Best new music\n\nThe full-length debut from t...</td>
    </tr>
    <tr>
      <th>2131</th>
      <td>Amazing Baby</td>
      <td>Rewild</td>
      <td>6.1</td>
      <td>Nate Patrin</td>
      <td>http://pitchfork.com/reviews/albums/13286-rewild/</td>
      <td>These MGMT buddies have been the focus of a co...</td>
    </tr>
    <tr>
      <th>1065</th>
      <td>Psychedelic Horseshit</td>
      <td>Laced</td>
      <td>7.3</td>
      <td>Marc Masters</td>
      <td>http://pitchfork.com/reviews/albums/15425-laced/</td>
      <td>Now a duo, the self-proclaimed shitgaze band i...</td>
    </tr>
  </tbody>
</table>
</div>



## Exploring the reviews data set


```python
#Let's explore the data we've got a bit

print('# of reviews: ', len(sample_df.review))
print('# of reviewers: ', len(sample_df.reviewer.unique()))

```

    # of reviews:  2000
    # of reviewers:  186
    


```python
#Histogram to look at the spread of reviewers
plt.title('How Prolific are the Reviewers?')
plt.xlabel('Quantity of Reviews')
plt.ylabel('Number of Reviewers')
plt.hist(sample_df.groupby('reviewer').review.count(), bins=40)
```




    (array([ 80.,  19.,  26.,  12.,   7.,   2.,   6.,   3.,   4.,   4.,   2.,
              3.,   2.,   3.,   2.,   0.,   3.,   1.,   0.,   1.,   0.,   1.,
              0.,   0.,   1.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,
              0.,   1.,   0.,   0.,   0.,   0.,   1.]),
     array([   1. ,    3.5,    6. ,    8.5,   11. ,   13.5,   16. ,   18.5,
              21. ,   23.5,   26. ,   28.5,   31. ,   33.5,   36. ,   38.5,
              41. ,   43.5,   46. ,   48.5,   51. ,   53.5,   56. ,   58.5,
              61. ,   63.5,   66. ,   68.5,   71. ,   73.5,   76. ,   78.5,
              81. ,   83.5,   86. ,   88.5,   91. ,   93.5,   96. ,   98.5,
             101. ]),
     <a list of 40 Patch objects>)




    
![png](output_13_1.png)
    



```python

top_5_reviewers = sample_df.groupby('reviewer').review.count().nlargest(5)
print('The 5 most prolific reviewers:\n', top_5_reviewers)

```

    The 5 most prolific reviewers:
     reviewer
    Joe Tangari           101
    Stephen M. Deusner     88
    Brian Howe             67
    Ian Cohen              65
    Marc Hogan             61
    Name: review, dtype: int64
    


```python
#pull the names of all reviewers with >20 reviews
#use that to get average reviews for relatively prolific reviewers
floor_score = 20
df_count = sample_df.groupby('reviewer').count()
df_mean = sample_df.groupby('reviewer').mean()


plt.title('Average score for reviewers with >%i reviews' %floor_score)
plt.ylabel('# Reviewers')
plt.xlabel('Score')
plt.hist(df_mean[sample_df.groupby('reviewer').count().review>floor_score].score)

```




    (array([ 4.,  5.,  2.,  1.,  5.,  6.,  3.,  1.,  2.,  2.]),
     array([ 6.28275862,  6.43125695,  6.57975528,  6.72825362,  6.87675195,
             7.02525028,  7.17374861,  7.32224694,  7.47074527,  7.6192436 ,
             7.76774194]),
     <a list of 10 Patch objects>)




    
![png](output_15_1.png)
    



```python
cutoff_score = 7
print('Percent of reviews are \'good\' new music (>%i.0): ' %cutoff_score, sum(sample_df.score>7.0)/sum(sample_df.score>0)*100)
#originally I had a cutoff_score of 8, but 7 seemed easier for my poor little model
```

    Percent of reviews are 'good' new music (>7.0):  54.25
    


```python
#this concludes the exploratory analysis
sample_df.head()
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>album</th>
      <th>score</th>
      <th>reviewer</th>
      <th>url</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3454</th>
      <td>Flying</td>
      <td>Faces of the Night</td>
      <td>5.8</td>
      <td>Andrew Gaerig</td>
      <td>http://pitchfork.com/reviews/albums/11490-face...</td>
      <td>After playing avant-pop that fused Brooklyn's ...</td>
    </tr>
    <tr>
      <th>3584</th>
      <td>Arp</td>
      <td>In Light</td>
      <td>7.6</td>
      <td>Mark Richardson</td>
      <td>http://pitchfork.com/reviews/albums/11353-in-l...</td>
      <td>Former Tussle member Alexis Georgopoulos reinv...</td>
    </tr>
    <tr>
      <th>2855</th>
      <td>The Very Best</td>
      <td>Warm Heart of Africa</td>
      <td>8.6</td>
      <td>Brian Howe</td>
      <td>http://pitchfork.com/reviews/albums/13518-warm...</td>
      <td>Best new music\n\nThe full-length debut from t...</td>
    </tr>
    <tr>
      <th>2131</th>
      <td>Amazing Baby</td>
      <td>Rewild</td>
      <td>6.1</td>
      <td>Nate Patrin</td>
      <td>http://pitchfork.com/reviews/albums/13286-rewild/</td>
      <td>These MGMT buddies have been the focus of a co...</td>
    </tr>
    <tr>
      <th>1065</th>
      <td>Psychedelic Horseshit</td>
      <td>Laced</td>
      <td>7.3</td>
      <td>Marc Masters</td>
      <td>http://pitchfork.com/reviews/albums/15425-laced/</td>
      <td>Now a duo, the self-proclaimed shitgaze band i...</td>
    </tr>
  </tbody>
</table>
</div>



## Train Classifier


```python
#Now we'll transform each review into a 'bag of words' using sklearn, in order to create input for our models
#we'll also make a y data frame, determining if the reviews are best new music or not
bnm = sample_df.score>cutoff_score
y = bnm.astype(int).values

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(min_df = 0)
vectorizer.fit(sample_df.review)
x = vectorizer.transform(sample_df.review)
x = x.toarray()

print('Number of words analyzed: ', len(vectorizer.get_feature_names()))
print('Average words per article: ', np.array([i.sum() for i in x]).mean())


```

    Number of words analyzed:  49458
    Average words per article:  647.863
    


```python
#Same as above but as a function
#critics is the dataframe of reviews, etc.
from sklearn.feature_extraction.text import CountVectorizer

def make_xy(critics, vectorizer=None):
    bnm = critics.score>cutoff_score
    y = bnm.astype(int).values

    vectorizer = CountVectorizer(min_df = 0)
    vectorizer.fit(critics.review)
    x = vectorizer.transform(critics.review)
    x = x.toarray()
    
    return x, y

X, Y = make_xy(sample_df)

print('Number of words analyzed: ', len(vectorizer.get_feature_names()))
print('Average words per article: ', np.array([i.sum() for i in X]).mean())

```

    Number of words analyzed:  49458
    Average words per article:  647.863
    


```python
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

#split our data into training data (80%) and testing (20%)
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.2)

#fit the naive bayes model
nb = MultinomialNB(alpha=0.7) 
nb.fit(xtrain, ytrain)

#test training prediction
print('training accuracy: ', sum(nb.predict(xtrain)==ytrain)/len(ytrain))
print('testing accuracy: ', sum(nb.predict(xtest)==ytest)/len(ytest))
#well this model is most definitely overfit - training performance is much better than testing
#also with just 15% of music as bnm, I'm concerned with 81% accuracy

```

    training accuracy:  0.993125
    testing accuracy:  0.6525
    


```python
#let's assess whether our model is well-calibrated (i.e. whether its confidence % is about equal to its accuracy %)
hst = plt.hist(nb.predict_proba(xtest)[:,1], bins=20)

```


    
![png](output_22_0.png)
    



```python

bin_counts = hst[0]
probabilities = nb.predict_proba(xtest)
digits = np.digitize(probabilities[:,1], hst[1])

#next step is to figure out what % of each bin in our test data is fresh
#so we'll need to assign ytest to bins per digits
binframe = pd.DataFrame({'y':ytest, 'bin':digits})
bnm_prob = binframe.groupby('bin').sum()/binframe.groupby('bin').count()

#number of reviews in each bin divided by the total number of (test) reviews
pct_df = binframe.groupby('bin').count()/binframe.bin.count()

#pct_df won't have the right # of items if the bins aren't nicely distributed, so we'll pad it
ind = list(range(1,len(hst[0])+2))
indy_df = pd.DataFrame({'b':np.zeros(len(ind))}, index=ind)
indy_df = indy_df.join(pct_df)
indy_df = indy_df.max(axis=1)

#plot the cumulative distribution function
plt.xlabel('P(fresh)')
plt.ylabel('P(predicted fresh)')
plt.title('The model is poorly calibrated, & overconfident at both extremes')

#plt.plot(hst[1][:-1], np.cumsum(pct_df.values),'.')
plt.plot(hst[1], np.cumsum(indy_df.values),'.')
plt.plot(hst[1][:-1],hst[1][:-1], alpha=.5)

```




    [<matplotlib.lines.Line2D at 0x2783076c208>]




    
![png](output_23_1.png)
    



```python

```


```python

```


```python
#So this model is poorly calibrated, and its test accuracy is not too impressive (although better 
#than random guessing, at least)
#hopefully we can improve it by adjusting our hyperparameters
#alpha, our smoothing parameter, will help decrease the pull of any particular variable


```


```python
#sklearn.cross_validation.cross_val_score(clf, x, y, scorer=log_likelihood)

#the grid of parameters to search over
alphas = [0, .1, 1, 5, 10, 50]
min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]

#Find the best value for alpha and min_df, and the best classifier
best_alpha = None
best_min_df = None
max_loglike = -np.inf

for a in alphas:
    for min_df in min_dfs:         
        vectorizer = CountVectorizer(min_df = min_df)       
        X, Y = make_xy(sample_df, vectorizer)
        
        xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.2)
        #fit the naive bayes model
        nb = MultinomialNB()
        #nb.set_params(alpha=a) #i don't understand why this doesn't work
        #^alpha trouble
        nb.fit(xtrain, ytrain)
        #nll = cv_score(nb, X, Y) #function below already implements kfold validation
        nll = sklearn.cross_validation.cross_val_score(nb, xtest, ytest, scoring='neg_log_loss')
        if sum(nll) > max_loglike:
            max_loglike = sum(nll)
            best_alpha = alpha
            best_min_df = min_df
        
```


```python
print(max_loglike, '|', best_alpha, '|', best_min_df)

#log: 0.1/0.1
#same
```

    -26.4606640453 | 0.1 | 0.1
    


```python
import sklearn.model_selection
ll = sklearn.cross_validation.cross_val_score(nb, xtest, ytest, scoring='neg_log_loss')
sum(ll)
#-12... pretty bad! 0.683 is as good as random guessing...
#pre optimization: array([-12.71206784,  -9.92044569,  -9.87049272])
#the sum of neg log loss was -37.09
```




    -37.090407947805367




```python
#this cell obsolete

from sklearn.cross_validation import KFold

def cv_score(clf, x, y, score_func=0):
    result = 0
    nfold = 5
    for train, test in KFold(y.size, nfold):
        nb.fit(x[train], y[train])
        result += sklearn.cross_validation.cross_val_score(
            clf, x[test], y[test], scoring='neg_log_loss')
    return result/nfold


```

## Some interpretation


```python
#testing to see which words indicated good results vs. poor
words = np.array(vectorizer.get_feature_names())

x = np.eye(xtest.shape[1])
probs = nb.predict_log_proba(x)[:, 0]
ind = np.argsort(probs)
```


```python
print('good words: ',words[ind[:10]])
print('bad words: ',words[ind[-10:]])
```

    good words:  ['mingus' 'mercer' 'lucksmiths' 'bronson' 'bloom' 'vee' 'orcutt' 'chatham'
     'july' 'konk']
    bad words:  ['jenkinson' 'perkins' 'mehlan' 'jae' 'gough' 'watain' 'vikernes' 'slater'
     'rice' 'lytle']
    

Looks like the best predictor of an album's success is who made it. That makes perfect sense and actually gives me more confidence in the model...



```python
#custom review testing
print(nb.predict_proba(vectorizer.transform(
    ['awful tinny repetitive boring dull'])))
print(nb.predict_proba(vectorizer.transform(
    ['rich experimental complex excellent luxurious'])))
print(nb.predict_proba(vectorizer.transform(
    ['kanye'])))

```

    [[ 0.96405948  0.03594052]]
    [[ 0.20648061  0.79351939]]
    [[ 0.52786703  0.47213297]]
    

## Various testing for inputting alpha
I was able to get it to work outside of the gridsearch but not within



```python
cv_score(nb, x, y)
```




    array([-12.13488975, -11.74472142, -11.94645674])




```python
nb = MultinomialNB()
nb.set_params(alpha=.1)
nb.fit(xtrain, ytrain)
nb.predict(xtrain)
```




    array([0, 0, 1, ..., 0, 1, 0])




```python
vectorizer = CountVectorizer(min_df = min_df)       
X, Y = make_xy(sample_df, vectorizer)
        
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.2)
#fit the naive bayes model
nb = MultinomialNB(alpha=1)
#nb.set_params(alpha=1)
nb.fit(xtrain, ytrain)
#nll = cv_score(nb, X, Y) #function below already implements kfold validation
nll = sklearn.cross_validation.cross_val_score(nb, xtest, ytest, scoring='neg_log_loss')
sum(nll)
```




    -35.022955315311577




```python
alphas = [0, .1, 1, 5, 10, 50]
for a in alphas:
    print(type(a))
```

    <class 'int'>
    <class 'float'>
    <class 'int'>
    <class 'int'>
    <class 'int'>
    <class 'int'>
    


```python

```
